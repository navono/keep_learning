{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-04T06:45:14.922063Z",
     "start_time": "2024-05-04T06:45:08.359030Z"
    }
   },
   "source": [
    "import logging\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T06:45:37.356089Z",
     "start_time": "2024-05-04T06:45:23.945617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# exit cleanly if we are on a device that doesn't support torch.compile\n",
    "if torch.cuda.get_device_capability() < (7, 0):\n",
    "    print(\"Skipping because torch.compile is not supported on this device.\")\n",
    "else:\n",
    "    @torch.compile()\n",
    "    def fn(x, y):\n",
    "        z = x + y\n",
    "        return z + 2\n",
    "\n",
    "\n",
    "    inputs = (torch.ones(2, 2, device=\"cuda\"), torch.zeros(2, 2, device=\"cuda\"))\n",
    "\n",
    "\n",
    "    # print separator and reset dynamo\n",
    "    # between each example\n",
    "    def separator(name):\n",
    "        print(f\"==================={name}=========================\")\n",
    "        torch._dynamo.reset()\n",
    "\n",
    "\n",
    "    separator(\"Dynamo Tracing\")\n",
    "    # View dynamo tracing\n",
    "    # TORCH_LOGS=\"+dynamo\"\n",
    "    torch._logging.set_logs(dynamo=logging.DEBUG)\n",
    "    fn(*inputs)\n",
    "\n",
    "    separator(\"Traced Graph\")\n",
    "    # View traced graph\n",
    "    # TORCH_LOGS=\"graph\"\n",
    "    torch._logging.set_logs(graph=True)\n",
    "    fn(*inputs)\n",
    "\n",
    "    separator(\"Fusion Decisions\")\n",
    "    # View fusion decisions\n",
    "    # TORCH_LOGS=\"fusion\"\n",
    "    torch._logging.set_logs(fusion=True)\n",
    "    fn(*inputs)\n",
    "\n",
    "    separator(\"Output Code\")\n",
    "    # View output code generated by inductor\n",
    "    # TORCH_LOGS=\"output_code\"\n",
    "    torch._logging.set_logs(output_code=True)\n",
    "    fn(*inputs)\n",
    "\n",
    "    separator(\"\")"
   ],
   "id": "7c6c6b57996cb445",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0] torchdynamo start compiling fn C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py:5, stack (elided 5 frames):\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"<frozen runpy>\", line 88, in _run_code\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     app.launch_new_instance()\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     app.start()\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     self.io_loop.start()\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     self.asyncio_loop.run_forever()\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     self._run_once()\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     handle._run()\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     self._context.run(self._callback, *self._args)\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     await self.process_one()\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     await dispatch(*args)\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     await result\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     await super().execute_request(stream, ident, parent)\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     reply_content = await reply_content\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     res = shell.run_cell(\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     return super().run_cell(*args, **kwargs)\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     result = self._run_cell(\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     result = runner(coro)\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     coro.send(None)\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     if await self.run_code(code, result, async_=asy):\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py\", line 25, in <module>\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     fn(*inputs)\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]   File \"C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 451, in _fn\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0]     return fn(*args, **kwargs)\n",
      "V0504 14:45:34.387000 9496 torch\\_dynamo\\convert_frame.py:652] [0/0] \n",
      "I0504 14:45:34.390000 9496 torch\\_dynamo\\logging.py:55] [0/0] Step 1: torchdynamo start tracing fn C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py:5\n",
      "V0504 14:45:34.390000 9496 torch\\fx\\experimental\\symbolic_shapes.py:1980] [0/0] create_env\n",
      "V0504 14:45:34.406000 9496 torch\\_dynamo\\symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py:5 in fn\n",
      "V0504 14:45:34.406000 9496 torch\\_dynamo\\symbolic_convert.py:699] [0/0] [__trace_source]         @torch.compile()\n",
      "V0504 14:45:34.498000 9496 torch\\_dynamo\\symbolic_convert.py:725] [0/0] TRACE RESUME 0 []\n",
      "V0504 14:45:34.499000 9496 torch\\_dynamo\\symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py:7 in fn\n",
      "V0504 14:45:34.499000 9496 torch\\_dynamo\\symbolic_convert.py:699] [0/0] [__trace_source]             z = x + y\n",
      "V0504 14:45:34.500000 9496 torch\\_dynamo\\symbolic_convert.py:725] [0/0] TRACE LOAD_FAST x []\n",
      "V0504 14:45:34.501000 9496 torch\\_dynamo\\symbolic_convert.py:725] [0/0] TRACE LOAD_FAST y [LazyVariableTracker()]\n",
      "V0504 14:45:34.502000 9496 torch\\_dynamo\\symbolic_convert.py:725] [0/0] TRACE BINARY_OP 0 [LazyVariableTracker(), LazyVariableTracker()]\n",
      "V0504 14:45:34.503000 9496 torch\\_dynamo\\output_graph.py:1949] [0/0] create_graph_input L_x_ L['x']\n",
      "V0504 14:45:34.511000 9496 torch\\_dynamo\\variables\\builder.py:1873] [0/0] wrap_to_fake L['x'] (2, 2) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], constraint_sizes=[None, None], view_base_context=None, tensor_source=LocalSource(local_name='x', cell_or_freevar=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "V0504 14:45:34.515000 9496 torch\\_dynamo\\output_graph.py:1949] [0/0] create_graph_input L_y_ L['y']\n",
      "V0504 14:45:34.516000 9496 torch\\_dynamo\\variables\\builder.py:1873] [0/0] wrap_to_fake L['y'] (2, 2) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], constraint_sizes=[None, None], view_base_context=None, tensor_source=LocalSource(local_name='y', cell_or_freevar=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "V0504 14:45:34.518000 9496 torch\\_dynamo\\output_graph.py:1808] [0/0] [__trace_call] TRACE FX call add from C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py:7 in fn\n",
      "V0504 14:45:34.518000 9496 torch\\_dynamo\\output_graph.py:1808] [0/0] [__trace_call]         z = x + y\n",
      "V0504 14:45:34.518000 9496 torch\\_dynamo\\output_graph.py:1808] [0/0] [__trace_call]             ~~^~~\n",
      "V0504 14:45:34.528000 9496 torch\\_dynamo\\symbolic_convert.py:725] [0/0] TRACE STORE_FAST z [TensorVariable()]\n",
      "V0504 14:45:34.530000 9496 torch\\_dynamo\\symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py:8 in fn\n",
      "V0504 14:45:34.530000 9496 torch\\_dynamo\\symbolic_convert.py:699] [0/0] [__trace_source]             return z + 2\n",
      "V0504 14:45:34.530000 9496 torch\\_dynamo\\symbolic_convert.py:725] [0/0] TRACE LOAD_FAST z []\n",
      "V0504 14:45:34.532000 9496 torch\\_dynamo\\symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [TensorVariable()]\n",
      "V0504 14:45:34.533000 9496 torch\\_dynamo\\symbolic_convert.py:725] [0/0] TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable()]\n",
      "V0504 14:45:34.534000 9496 torch\\_dynamo\\output_graph.py:1808] [0/0] [__trace_call] TRACE FX call add_1 from C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py:8 in fn\n",
      "V0504 14:45:34.534000 9496 torch\\_dynamo\\output_graph.py:1808] [0/0] [__trace_call]         return z + 2\n",
      "V0504 14:45:34.534000 9496 torch\\_dynamo\\output_graph.py:1808] [0/0] [__trace_call]                ~~^~~\n",
      "V0504 14:45:34.536000 9496 torch\\_dynamo\\symbolic_convert.py:725] [0/0] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "I0504 14:45:34.537000 9496 torch\\_dynamo\\logging.py:55] [0/0] Step 1: torchdynamo done tracing fn (RETURN_VALUE)\n",
      "V0504 14:45:34.538000 9496 torch\\_dynamo\\symbolic_convert.py:2267] [0/0] RETURN_VALUE triggered compile\n",
      "V0504 14:45:34.539000 9496 torch\\_dynamo\\output_graph.py:870] [0/0] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py, line 8 in fn>], graph_break=False)\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code] TRACED GRAPH\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]  ===== __compiled_fn_0 =====\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]  C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]     def forward(self, L_x_ : torch.Tensor, L_y_ : torch.Tensor):\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]         l_x_ = L_x_\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]         l_y_ = L_y_\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]         \n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]         # File: C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py:7 in fn, code: z = x + y\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]         z = l_x_ + l_y_;  l_x_ = l_y_ = None\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]         \n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]         # File: C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py:8 in fn, code: return z + 2\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]         add_1 = z + 2;  z = None\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]         return (add_1,)\n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code]         \n",
      "V0504 14:45:34.540000 9496 torch\\_dynamo\\output_graph.py:1147] [0/0] [__graph_code] \n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph] Tabulate module missing, please install tabulate to log the graph in tabular format, logging code instead:\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph] TRACED GRAPH\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]  ===== __compiled_fn_0 =====\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]  C:\\Users\\ping\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]     def forward(self, L_x_ : torch.Tensor, L_y_ : torch.Tensor):\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]         l_x_ = L_x_\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]         l_y_ = L_y_\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]         \n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]         # File: C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py:7 in fn, code: z = x + y\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]         z = l_x_ + l_y_;  l_x_ = l_y_ = None\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]         \n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]         # File: C:\\Users\\ping\\AppData\\Local\\Temp\\ipykernel_1852\\547727389.py:8 in fn, code: return z + 2\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]         add_1 = z + 2;  z = None\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]         return (add_1,)\n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph]         \n",
      "V0504 14:45:34.541000 9496 torch\\_dynamo\\output_graph.py:1153] [0/0] [__graph] \n",
      "V0504 14:45:34.544000 9496 torch\\_dynamo\\output_graph.py:1154] [0/0] [__graph_sizes] TRACED GRAPH TENSOR SIZES\n",
      "V0504 14:45:34.544000 9496 torch\\_dynamo\\output_graph.py:1154] [0/0] [__graph_sizes] ===== __compiled_fn_0 =====\n",
      "V0504 14:45:34.544000 9496 torch\\_dynamo\\output_graph.py:1154] [0/0] [__graph_sizes] l_x_: (2, 2)\n",
      "V0504 14:45:34.544000 9496 torch\\_dynamo\\output_graph.py:1154] [0/0] [__graph_sizes] l_y_: (2, 2)\n",
      "V0504 14:45:34.544000 9496 torch\\_dynamo\\output_graph.py:1154] [0/0] [__graph_sizes] z: (2, 2)\n",
      "V0504 14:45:34.544000 9496 torch\\_dynamo\\output_graph.py:1154] [0/0] [__graph_sizes] add_1: (2, 2)\n",
      "V0504 14:45:34.544000 9496 torch\\_dynamo\\output_graph.py:1154] [0/0] [__graph_sizes] \n",
      "I0504 14:45:34.546000 9496 torch\\_dynamo\\logging.py:55] [0/0] Step 2: calling compiler function inductor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================Dynamo Tracing=========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "V0504 14:45:35.462000 9496 torch\\fx\\experimental\\symbolic_shapes.py:4119] [0/0] eval True == True [statically known]\n"
     ]
    },
    {
     "ename": "BackendCompilerFailed",
     "evalue": "backend='inductor' raised:\nRuntimeError: Cannot find a working triton installation. More information on installing Triton can be found at https://github.com/openai/triton\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mBackendCompilerFailed\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 25\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# View dynamo tracing\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# TORCH_LOGS=\"+dynamo\"\u001B[39;00m\n\u001B[0;32m     24\u001B[0m torch\u001B[38;5;241m.\u001B[39m_logging\u001B[38;5;241m.\u001B[39mset_logs(dynamo\u001B[38;5;241m=\u001B[39mlogging\u001B[38;5;241m.\u001B[39mDEBUG)\n\u001B[1;32m---> 25\u001B[0m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m separator(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraced Graph\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# View traced graph\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# TORCH_LOGS=\"graph\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:451\u001B[0m, in \u001B[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    449\u001B[0m prior \u001B[38;5;241m=\u001B[39m set_eval_frame(callback)\n\u001B[0;32m    450\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    453\u001B[0m     set_eval_frame(prior)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:921\u001B[0m, in \u001B[0;36mcatch_errors_wrapper.<locals>.catch_errors\u001B[1;34m(frame, cache_entry, frame_state)\u001B[0m\n\u001B[0;32m    917\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m hijacked_callback(frame, cache_entry, hooks, frame_state)\n\u001B[0;32m    919\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m compile_lock, _disable_current_modes():\n\u001B[0;32m    920\u001B[0m     \u001B[38;5;66;03m# skip=1: skip this frame\u001B[39;00m\n\u001B[1;32m--> 921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_entry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:786\u001B[0m, in \u001B[0;36mconvert_frame.<locals>._convert_frame\u001B[1;34m(frame, cache_entry, hooks, frame_state, skip)\u001B[0m\n\u001B[0;32m    784\u001B[0m counters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframes\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    785\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 786\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43minner_convert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    787\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_entry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[0;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    789\u001B[0m     counters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframes\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mok\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    790\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:400\u001B[0m, in \u001B[0;36mconvert_frame_assert.<locals>._convert_frame_assert\u001B[1;34m(frame, cache_entry, hooks, frame_state, skip)\u001B[0m\n\u001B[0;32m    386\u001B[0m compile_id \u001B[38;5;241m=\u001B[39m CompileId(frame_id, frame_compile_id)\n\u001B[0;32m    388\u001B[0m signpost_event(\n\u001B[0;32m    389\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdynamo\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    390\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_convert_frame_assert._compile\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    397\u001B[0m     },\n\u001B[0;32m    398\u001B[0m )\n\u001B[1;32m--> 400\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_compile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    401\u001B[0m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    402\u001B[0m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_globals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_locals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_builtins\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompiler_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mone_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexport\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexport_constraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    411\u001B[0m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[43m    \u001B[49m\u001B[43mframe_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mframe_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompile_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompile_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[43m    \u001B[49m\u001B[43mskip\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\contextlib.py:81\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[1;32m---> 81\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:676\u001B[0m, in \u001B[0;36m_compile\u001B[1;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_size, frame, frame_state, compile_id, skip)\u001B[0m\n\u001B[0;32m    674\u001B[0m fail_user_frame_lineno: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 676\u001B[0m     guarded_code \u001B[38;5;241m=\u001B[39m \u001B[43mcompile_inner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mone_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    677\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m guarded_code\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\n\u001B[0;32m    679\u001B[0m     Unsupported,\n\u001B[0;32m    680\u001B[0m     TorchRuntimeError,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    687\u001B[0m     BisectValidationException,\n\u001B[0;32m    688\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\utils.py:262\u001B[0m, in \u001B[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (dynamo_timed)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    261\u001B[0m     t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 262\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    263\u001B[0m     time_spent \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0\n\u001B[0;32m    264\u001B[0m compilation_time_metrics[key]\u001B[38;5;241m.\u001B[39mappend(time_spent)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:535\u001B[0m, in \u001B[0;36m_compile.<locals>.compile_inner\u001B[1;34m(code, one_graph, hooks, transform)\u001B[0m\n\u001B[0;32m    533\u001B[0m CompileContext\u001B[38;5;241m.\u001B[39mget()\u001B[38;5;241m.\u001B[39mattempt \u001B[38;5;241m=\u001B[39m attempt\n\u001B[0;32m    534\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 535\u001B[0m     out_code \u001B[38;5;241m=\u001B[39m \u001B[43mtransform_code_object\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    536\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mRestartAnalysis \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py:1036\u001B[0m, in \u001B[0;36mtransform_code_object\u001B[1;34m(code, transformations, safe)\u001B[0m\n\u001B[0;32m   1033\u001B[0m instructions \u001B[38;5;241m=\u001B[39m cleaned_instructions(code, safe)\n\u001B[0;32m   1034\u001B[0m propagate_line_nums(instructions)\n\u001B[1;32m-> 1036\u001B[0m \u001B[43mtransformations\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstructions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcode_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:165\u001B[0m, in \u001B[0;36mpreserve_global_state.<locals>._fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    163\u001B[0m cleanup \u001B[38;5;241m=\u001B[39m setup_compile_debug()\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 165\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    167\u001B[0m     cleanup\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:500\u001B[0m, in \u001B[0;36m_compile.<locals>.transform\u001B[1;34m(instructions, code_options)\u001B[0m\n\u001B[0;32m    498\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    499\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tracing(tracer\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39mtracing_context), tracer\u001B[38;5;241m.\u001B[39mset_current_tx():\n\u001B[1;32m--> 500\u001B[0m         \u001B[43mtracer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mUnspecializeRestartAnalysis:\n\u001B[0;32m    502\u001B[0m     speculation_log\u001B[38;5;241m.\u001B[39mclear()\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:2149\u001B[0m, in \u001B[0;36mInstructionTranslator.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2148\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m-> 2149\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:810\u001B[0m, in \u001B[0;36mInstructionTranslatorBase.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    805\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    806\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39mpush_tx(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    807\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m (\n\u001B[0;32m    808\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstruction_pointer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39mshould_exit\n\u001B[1;32m--> 810\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    811\u001B[0m     ):\n\u001B[0;32m    812\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m BackendCompilerFailed:\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:773\u001B[0m, in \u001B[0;36mInstructionTranslatorBase.step\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    769\u001B[0m         unimplemented(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmissing: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minst\u001B[38;5;241m.\u001B[39mopname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    770\u001B[0m     TracingContext\u001B[38;5;241m.\u001B[39mset_current_loc(\n\u001B[0;32m    771\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_code\u001B[38;5;241m.\u001B[39mco_filename, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineno, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_code\u001B[38;5;241m.\u001B[39mco_name\n\u001B[0;32m    772\u001B[0m     )\n\u001B[1;32m--> 773\u001B[0m     \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43minst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    775\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inst\u001B[38;5;241m.\u001B[39mopname \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRETURN_VALUE\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    776\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m Unsupported:\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:2268\u001B[0m, in \u001B[0;36mInstructionTranslator.RETURN_VALUE\u001B[1;34m(self, inst)\u001B[0m\n\u001B[0;32m   2263\u001B[0m _step_logger()(\n\u001B[0;32m   2264\u001B[0m     logging\u001B[38;5;241m.\u001B[39mINFO,\n\u001B[0;32m   2265\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorchdynamo done tracing \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_code\u001B[38;5;241m.\u001B[39mco_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (RETURN_VALUE)\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2266\u001B[0m )\n\u001B[0;32m   2267\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRETURN_VALUE triggered compile\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 2268\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_subgraph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2269\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreason\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mGraphCompileReason\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2271\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreturn_value\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mframe_summary\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph_break\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m   2272\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2273\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2274\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39madd_output_instructions([create_instruction(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRETURN_VALUE\u001B[39m\u001B[38;5;124m\"\u001B[39m)])\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:971\u001B[0m, in \u001B[0;36mOutputGraph.compile_subgraph\u001B[1;34m(self, tx, partial_convert, reason)\u001B[0m\n\u001B[0;32m    968\u001B[0m     append_prefix_insts()\n\u001B[0;32m    969\u001B[0m     \u001B[38;5;66;03m# optimization to generate better code in a common case\u001B[39;00m\n\u001B[0;32m    970\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_output_instructions(\n\u001B[1;32m--> 971\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_and_call_fx_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mreversed\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstack_values\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mroot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    972\u001B[0m         \u001B[38;5;241m+\u001B[39m [create_instruction(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUNPACK_SEQUENCE\u001B[39m\u001B[38;5;124m\"\u001B[39m, arg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(stack_values))]\n\u001B[0;32m    973\u001B[0m     )\n\u001B[0;32m    974\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    975\u001B[0m     graph_output_var \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnew_var(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph_out\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\contextlib.py:81\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[1;32m---> 81\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1168\u001B[0m, in \u001B[0;36mOutputGraph.compile_and_call_fx_graph\u001B[1;34m(self, tx, rv, root)\u001B[0m\n\u001B[0;32m   1165\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtracing_context\u001B[38;5;241m.\u001B[39mfake_mode \u001B[38;5;241m=\u001B[39m backend_fake_mode\n\u001B[0;32m   1167\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrestore_global_state():\n\u001B[1;32m-> 1168\u001B[0m     compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_user_compiler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1169\u001B[0m compiled_fn \u001B[38;5;241m=\u001B[39m disable(compiled_fn)\n\u001B[0;32m   1171\u001B[0m counters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstats\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munique_graphs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\utils.py:262\u001B[0m, in \u001B[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (dynamo_timed)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    261\u001B[0m     t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 262\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    263\u001B[0m     time_spent \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0\n\u001B[0;32m    264\u001B[0m compilation_time_metrics[key]\u001B[38;5;241m.\u001B[39mappend(time_spent)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1241\u001B[0m, in \u001B[0;36mOutputGraph.call_user_compiler\u001B[1;34m(self, gm)\u001B[0m\n\u001B[0;32m   1239\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m   1240\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1241\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m BackendCompilerFailed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompiler_fn, e)\u001B[38;5;241m.\u001B[39mwith_traceback(\n\u001B[0;32m   1242\u001B[0m         e\u001B[38;5;241m.\u001B[39m__traceback__\n\u001B[0;32m   1243\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1245\u001B[0m signpost_event(\n\u001B[0;32m   1246\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdynamo\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1247\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOutputGraph.call_user_compiler\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1253\u001B[0m     },\n\u001B[0;32m   1254\u001B[0m )\n\u001B[0;32m   1256\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiled_fn\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1222\u001B[0m, in \u001B[0;36mOutputGraph.call_user_compiler\u001B[1;34m(self, gm)\u001B[0m\n\u001B[0;32m   1220\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mverify_correctness:\n\u001B[0;32m   1221\u001B[0m     compiler_fn \u001B[38;5;241m=\u001B[39m WrapperBackend(compiler_fn)\n\u001B[1;32m-> 1222\u001B[0m compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexample_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1223\u001B[0m _step_logger()(logging\u001B[38;5;241m.\u001B[39mINFO, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdone compiler function \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1224\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(compiled_fn), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompiler_fn did not return callable\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py:117\u001B[0m, in \u001B[0;36mwrap_backend_debug.<locals>.debug_wrapper\u001B[1;34m(gm, example_inputs, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     compiled_gm \u001B[38;5;241m=\u001B[39m \u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiled_gm\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\__init__.py:1729\u001B[0m, in \u001B[0;36m_TorchCompileInductorWrapper.__call__\u001B[1;34m(self, model_, inputs_)\u001B[0m\n\u001B[0;32m   1726\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, model_, inputs_):\n\u001B[0;32m   1727\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_inductor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompile_fx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compile_fx\n\u001B[1;32m-> 1729\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompile_fx\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig_patches\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\contextlib.py:81\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[1;32m---> 81\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1330\u001B[0m, in \u001B[0;36mcompile_fx\u001B[1;34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001B[0m\n\u001B[0;32m   1325\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m inference_compiler(unlifted_gm, example_inputs_)\n\u001B[0;32m   1327\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m V\u001B[38;5;241m.\u001B[39mset_fake_mode(fake_mode), torch\u001B[38;5;241m.\u001B[39m_guards\u001B[38;5;241m.\u001B[39mtracing(\n\u001B[0;32m   1328\u001B[0m     tracing_context\n\u001B[0;32m   1329\u001B[0m ), compiled_autograd\u001B[38;5;241m.\u001B[39mdisable():\n\u001B[1;32m-> 1330\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43maot_autograd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1331\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfw_compiler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfw_compiler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1332\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbw_compiler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbw_compiler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1333\u001B[0m \u001B[43m        \u001B[49m\u001B[43minference_compiler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minference_compiler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1334\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecompositions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecompositions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1335\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartition_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartition_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1336\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_inference_input_mutations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1337\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs_\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py:58\u001B[0m, in \u001B[0;36maot_autograd.<locals>.compiler_fn\u001B[1;34m(gm, example_inputs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;66;03m# NB: NOT cloned!\u001B[39;00m\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m enable_aot_logging(), patch_config:\n\u001B[1;32m---> 58\u001B[0m         cg \u001B[38;5;241m=\u001B[39m \u001B[43maot_module_simplified\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     59\u001B[0m         counters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maot_autograd\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mok\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     60\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m disable(cg)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:903\u001B[0m, in \u001B[0;36maot_module_simplified\u001B[1;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler)\u001B[0m\n\u001B[0;32m    887\u001B[0m aot_config \u001B[38;5;241m=\u001B[39m AOTConfig(\n\u001B[0;32m    888\u001B[0m     fw_compiler\u001B[38;5;241m=\u001B[39mfw_compiler,\n\u001B[0;32m    889\u001B[0m     bw_compiler\u001B[38;5;241m=\u001B[39mbw_compiler,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    899\u001B[0m     no_tangents\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    900\u001B[0m )\n\u001B[0;32m    902\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m compiled_autograd\u001B[38;5;241m.\u001B[39mdisable():\n\u001B[1;32m--> 903\u001B[0m     compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_aot_dispatcher_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    904\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunctional_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    905\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfull_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    906\u001B[0m \u001B[43m        \u001B[49m\u001B[43maot_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    907\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    909\u001B[0m \u001B[38;5;66;03m# TODO: There is something deeply wrong here; compiled_fn running with\u001B[39;00m\n\u001B[0;32m    910\u001B[0m \u001B[38;5;66;03m# the boxed calling convention, but aot_module_simplified somehow\u001B[39;00m\n\u001B[0;32m    911\u001B[0m \u001B[38;5;66;03m# historically returned a function that was not the boxed calling\u001B[39;00m\n\u001B[0;32m    912\u001B[0m \u001B[38;5;66;03m# convention.  This should get fixed...\u001B[39;00m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;241m*\u001B[39mruntime_args):\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\utils.py:262\u001B[0m, in \u001B[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (dynamo_timed)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    261\u001B[0m     t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 262\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    263\u001B[0m     time_spent \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0\n\u001B[0;32m    264\u001B[0m compilation_time_metrics[key]\u001B[38;5;241m.\u001B[39mappend(time_spent)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:628\u001B[0m, in \u001B[0;36mcreate_aot_dispatcher_function\u001B[1;34m(flat_fn, flat_args, aot_config)\u001B[0m\n\u001B[0;32m    625\u001B[0m compiler_fn \u001B[38;5;241m=\u001B[39m partial(aot_wrapper_dedupe, compiler_fn\u001B[38;5;241m=\u001B[39mcompiler_fn)\n\u001B[0;32m    626\u001B[0m \u001B[38;5;66;03m# You can put more passes here\u001B[39;00m\n\u001B[1;32m--> 628\u001B[0m compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mflat_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfake_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maot_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfw_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfw_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    629\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m aot_config\u001B[38;5;241m.\u001B[39mis_export:\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;66;03m# During export, we don't get back a callable - we get back the raw fx graph\u001B[39;00m\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;66;03m# (either a joint or an inference-only graph)\u001B[39;00m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(compiled_fn, torch\u001B[38;5;241m.\u001B[39mfx\u001B[38;5;241m.\u001B[39mGraphModule)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\runtime_wrappers.py:443\u001B[0m, in \u001B[0;36maot_wrapper_dedupe\u001B[1;34m(flat_fn, flat_args, aot_config, compiler_fn, fw_metadata)\u001B[0m\n\u001B[0;32m    440\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    442\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ok:\n\u001B[1;32m--> 443\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mflat_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mleaf_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maot_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfw_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfw_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m requires_subclass_dispatch(leaf_flat_args, fw_metadata):\n\u001B[0;32m    446\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    447\u001B[0m \u001B[38;5;250m            \u001B[39m\u001B[38;5;124;03m\"\"\"\\\u001B[39;00m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;124;03mEncountered duplicate inputs that are mutated in the graph, but at least one input/output\u001B[39;00m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;124;03mto the graph is a tensor subclass. This is not supported today. You can try to\u001B[39;00m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;124;03mremove the aliasing yourself as a workaround, or otherwise file an issue on github.\"\"\"\u001B[39;00m\n\u001B[0;32m    451\u001B[0m         )\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\runtime_wrappers.py:648\u001B[0m, in \u001B[0;36maot_wrapper_synthetic_base\u001B[1;34m(flat_fn, flat_args, aot_config, fw_metadata, needs_autograd, compiler_fn)\u001B[0m\n\u001B[0;32m    646\u001B[0m \u001B[38;5;66;03m# Happy path: we don't need synthetic bases\u001B[39;00m\n\u001B[0;32m    647\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synthetic_base_info \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 648\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mflat_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maot_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfw_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfw_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    650\u001B[0m \u001B[38;5;66;03m# export path: ban synthetic bases for now, add later if requested.\u001B[39;00m\n\u001B[0;32m    651\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m requires_subclass_dispatch(flat_args, fw_metadata):\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py:119\u001B[0m, in \u001B[0;36maot_dispatch_base\u001B[1;34m(flat_fn, flat_args, aot_config, fw_metadata)\u001B[0m\n\u001B[0;32m    112\u001B[0m     tracing_context\u001B[38;5;241m.\u001B[39mfw_metadata \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    113\u001B[0m         fw_metadata\n\u001B[0;32m    114\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m maybe_subclass_meta \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    115\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m maybe_subclass_meta\u001B[38;5;241m.\u001B[39mfw_metadata\n\u001B[0;32m    116\u001B[0m     )\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m TracingContext\u001B[38;5;241m.\u001B[39mreport_output_strides() \u001B[38;5;28;01mas\u001B[39;00m fwd_output_strides:\n\u001B[1;32m--> 119\u001B[0m     compiled_fw \u001B[38;5;241m=\u001B[39m \u001B[43mcompiler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfw_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdated_flat_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;66;03m# see note: [Returning Fake Tensors on First AOT Autograd Call]\u001B[39;00m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tracing_context \u001B[38;5;129;01mand\u001B[39;00m tracing_context\u001B[38;5;241m.\u001B[39mfakify_first_call:\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\utils.py:262\u001B[0m, in \u001B[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (dynamo_timed)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    261\u001B[0m     t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 262\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    263\u001B[0m     time_spent \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0\n\u001B[0;32m    264\u001B[0m compilation_time_metrics[key]\u001B[38;5;241m.\u001B[39mappend(time_spent)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1257\u001B[0m, in \u001B[0;36mcompile_fx.<locals>.fw_compiler_base\u001B[1;34m(model, example_inputs, is_inference)\u001B[0m\n\u001B[0;32m   1249\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m orig_output_end_idx \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m num_model_outputs\n\u001B[0;32m   1251\u001B[0m     user_visible_outputs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1252\u001B[0m         n\u001B[38;5;241m.\u001B[39mname\n\u001B[0;32m   1253\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m model_outputs[original_output_start_index:orig_output_end_idx]\n\u001B[0;32m   1254\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(n, torch\u001B[38;5;241m.\u001B[39mfx\u001B[38;5;241m.\u001B[39mNode)\n\u001B[0;32m   1255\u001B[0m     }\n\u001B[1;32m-> 1257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_compile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1258\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1259\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1260\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_fixed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1261\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcudagraphs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcudagraphs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1262\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgraph_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_inference\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_inference\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mboxed_forward_device_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforward_device\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1265\u001B[0m \u001B[43m    \u001B[49m\u001B[43muser_visible_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_visible_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1266\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py:83\u001B[0m, in \u001B[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001B[1;34m(gm, example_inputs, **kwargs)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m config\u001B[38;5;241m.\u001B[39mrepro_after \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdynamo\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maot\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001B[39;00m\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;66;03m# with fake inputs\u001B[39;00m\n\u001B[1;32m---> 83\u001B[0m     inner_compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001B[39;00m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;66;03m# need a different serialization strategy\u001B[39;00m\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mrepro_after \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maot\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\debug.py:304\u001B[0m, in \u001B[0;36mDebugContext.wrap.<locals>.inner\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(fn)\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    303\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m DebugContext():\n\u001B[1;32m--> 304\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\contextlib.py:81\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[1;32m---> 81\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\contextlib.py:81\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[1;32m---> 81\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\utils.py:262\u001B[0m, in \u001B[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (dynamo_timed)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    261\u001B[0m     t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 262\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    263\u001B[0m     time_spent \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0\n\u001B[0;32m    264\u001B[0m compilation_time_metrics[key]\u001B[38;5;241m.\u001B[39mappend(time_spent)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:438\u001B[0m, in \u001B[0;36mcompile_fx_inner\u001B[1;34m(gm, example_inputs, cudagraphs, num_fixed, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, boxed_forward_device_index, user_visible_outputs, layout_opt, extern_node_serializer)\u001B[0m\n\u001B[0;32m    434\u001B[0m     compiled_graph \u001B[38;5;241m=\u001B[39m FxGraphCache\u001B[38;5;241m.\u001B[39mload(\n\u001B[0;32m    435\u001B[0m         fx_codegen_and_compile, gm, example_inputs, graph_kwargs\n\u001B[0;32m    436\u001B[0m     )\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 438\u001B[0m     compiled_graph \u001B[38;5;241m=\u001B[39m \u001B[43mfx_codegen_and_compile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    439\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgraph_kwargs\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m    440\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    442\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFX codegen and compilation took \u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m, time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start)\n\u001B[0;32m    444\u001B[0m \u001B[38;5;66;03m# check cudagraph disabling reasons from inductor lowering\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:714\u001B[0m, in \u001B[0;36mfx_codegen_and_compile\u001B[1;34m(gm, example_inputs, cudagraphs, num_fixed, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, user_visible_outputs, layout_opt, extern_node_serializer)\u001B[0m\n\u001B[0;32m    711\u001B[0m             output_strides\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    713\u001B[0m metrics_helper \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39mCachedMetricsHelper()\n\u001B[1;32m--> 714\u001B[0m compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_to_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m V\u001B[38;5;241m.\u001B[39maot_compilation \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    717\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m compiled_fn\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\graph.py:1307\u001B[0m, in \u001B[0;36mGraphLowering.compile_to_fn\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1303\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m AotCodeCompiler\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[0;32m   1304\u001B[0m         \u001B[38;5;28mself\u001B[39m, code, serialized_extern_kernel_nodes, cuda\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcuda\n\u001B[0;32m   1305\u001B[0m     )\n\u001B[0;32m   1306\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1307\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_to_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mcall\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\utils.py:262\u001B[0m, in \u001B[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (dynamo_timed)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    261\u001B[0m     t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 262\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    263\u001B[0m     time_spent \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0\n\u001B[0;32m    264\u001B[0m compilation_time_metrics[key]\u001B[38;5;241m.\u001B[39mappend(time_spent)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\graph.py:1250\u001B[0m, in \u001B[0;36mGraphLowering.compile_to_module\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1245\u001B[0m \u001B[38;5;129m@dynamo_timed\u001B[39m(phase_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode_gen\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1246\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompile_to_module\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1247\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcodecache\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PyCodeCache\n\u001B[0;32m   1249\u001B[0m     code, linemap \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m-> 1250\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcodegen_with_cpp_wrapper() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcpp_wrapper \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcodegen\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1251\u001B[0m     )\n\u001B[0;32m   1252\u001B[0m     linemap \u001B[38;5;241m=\u001B[39m [(line_no, node\u001B[38;5;241m.\u001B[39mstack_trace) \u001B[38;5;28;01mfor\u001B[39;00m line_no, node \u001B[38;5;129;01min\u001B[39;00m linemap]\n\u001B[0;32m   1253\u001B[0m     key, path \u001B[38;5;241m=\u001B[39m PyCodeCache\u001B[38;5;241m.\u001B[39mwrite(code)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\graph.py:1205\u001B[0m, in \u001B[0;36mGraphLowering.codegen\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1201\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscheduler\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Scheduler\n\u001B[0;32m   1203\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_wrapper_code()\n\u001B[1;32m-> 1205\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler \u001B[38;5;241m=\u001B[39m \u001B[43mScheduler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuffers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1206\u001B[0m V\u001B[38;5;241m.\u001B[39mdebug\u001B[38;5;241m.\u001B[39mdraw_orig_fx_graph(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morig_gm, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39mnodes)\n\u001B[0;32m   1208\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39mcodegen()\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_dynamo\\utils.py:262\u001B[0m, in \u001B[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (dynamo_timed)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    261\u001B[0m     t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 262\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    263\u001B[0m     time_spent \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0\n\u001B[0;32m    264\u001B[0m compilation_time_metrics[key]\u001B[38;5;241m.\u001B[39mappend(time_spent)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1267\u001B[0m, in \u001B[0;36mScheduler.__init__\u001B[1;34m(self, nodes)\u001B[0m\n\u001B[0;32m   1261\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnodes \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   1262\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mavailable_buffer_names \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1263\u001B[0m     \u001B[38;5;241m*\u001B[39mV\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mgraph_inputs\u001B[38;5;241m.\u001B[39mkeys(),\n\u001B[0;32m   1264\u001B[0m     \u001B[38;5;241m*\u001B[39mV\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mconstants\u001B[38;5;241m.\u001B[39mkeys(),\n\u001B[0;32m   1265\u001B[0m }\n\u001B[1;32m-> 1267\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnodes \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_scheduler_node\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m   1269\u001B[0m \u001B[38;5;66;03m# some new constants could have been created above\u001B[39;00m\n\u001B[0;32m   1270\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mavailable_buffer_names\u001B[38;5;241m.\u001B[39mupdate(V\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mconstants\u001B[38;5;241m.\u001B[39mkeys())\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1267\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m   1261\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnodes \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   1262\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mavailable_buffer_names \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1263\u001B[0m     \u001B[38;5;241m*\u001B[39mV\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mgraph_inputs\u001B[38;5;241m.\u001B[39mkeys(),\n\u001B[0;32m   1264\u001B[0m     \u001B[38;5;241m*\u001B[39mV\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mconstants\u001B[38;5;241m.\u001B[39mkeys(),\n\u001B[0;32m   1265\u001B[0m }\n\u001B[1;32m-> 1267\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnodes \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_scheduler_node\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m nodes]\n\u001B[0;32m   1269\u001B[0m \u001B[38;5;66;03m# some new constants could have been created above\u001B[39;00m\n\u001B[0;32m   1270\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mavailable_buffer_names\u001B[38;5;241m.\u001B[39mupdate(V\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mconstants\u001B[38;5;241m.\u001B[39mkeys())\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1358\u001B[0m, in \u001B[0;36mScheduler.create_scheduler_node\u001B[1;34m(self, node)\u001B[0m\n\u001B[0;32m   1356\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m NopKernelSchedulerNode(\u001B[38;5;28mself\u001B[39m, node)\n\u001B[0;32m   1357\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node, (ir\u001B[38;5;241m.\u001B[39mComputedBuffer, ir\u001B[38;5;241m.\u001B[39mTemplateBuffer)):\n\u001B[1;32m-> 1358\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSchedulerNode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1359\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node, ir\u001B[38;5;241m.\u001B[39mExternKernel):\n\u001B[0;32m   1360\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ExternKernelSchedulerNode(\u001B[38;5;28mself\u001B[39m, node)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:687\u001B[0m, in \u001B[0;36mSchedulerNode.__init__\u001B[1;34m(self, scheduler, node)\u001B[0m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    683\u001B[0m     scheduler: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mScheduler\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    684\u001B[0m     node: Union[ir\u001B[38;5;241m.\u001B[39mComputedBuffer, ir\u001B[38;5;241m.\u001B[39mTemplateBuffer],\n\u001B[0;32m    685\u001B[0m ):\n\u001B[0;32m    686\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(scheduler, node)\n\u001B[1;32m--> 687\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_attrs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:698\u001B[0m, in \u001B[0;36mSchedulerNode._compute_attrs\u001B[1;34m(self, extra_indexing_constraints)\u001B[0m\n\u001B[0;32m    693\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode, (ir\u001B[38;5;241m.\u001B[39mComputedBuffer, ir\u001B[38;5;241m.\u001B[39mTemplateBuffer))\n\u001B[0;32m    694\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sizes, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_body \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39msimplify_and_reorder(\n\u001B[0;32m    695\u001B[0m     extra_indexing_constraints\u001B[38;5;241m=\u001B[39mextra_indexing_constraints\n\u001B[0;32m    696\u001B[0m )\n\u001B[1;32m--> 698\u001B[0m group_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_backend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgroup_fn\n\u001B[0;32m    699\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroup \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39mget_device(), group_fn(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sizes))\n\u001B[0;32m    701\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode, ir\u001B[38;5;241m.\u001B[39mTemplateBuffer):\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:2276\u001B[0m, in \u001B[0;36mScheduler.get_backend\u001B[1;34m(self, device)\u001B[0m\n\u001B[0;32m   2274\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_backend\u001B[39m(\u001B[38;5;28mself\u001B[39m, device: torch\u001B[38;5;241m.\u001B[39mdevice):\n\u001B[0;32m   2275\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackends:\n\u001B[1;32m-> 2276\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackends[device] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_backend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackends[device]\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\keep-learning-B7T8eeln-py3.11\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:2268\u001B[0m, in \u001B[0;36mScheduler.create_backend\u001B[1;34m(self, device)\u001B[0m\n\u001B[0;32m   2264\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   2265\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice_props\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice_props\u001B[38;5;241m.\u001B[39mmajor\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice_props\u001B[38;5;241m.\u001B[39mminor\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# noqa: B950\u001B[39;00m\n\u001B[0;32m   2266\u001B[0m         )\n\u001B[0;32m   2267\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2268\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   2269\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot find a working triton installation. More information on installing Triton can be found at https://github.com/openai/triton\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# noqa: B950\u001B[39;00m\n\u001B[0;32m   2270\u001B[0m         )\n\u001B[0;32m   2272\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m device_scheduling(\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[1;31mBackendCompilerFailed\u001B[0m: backend='inductor' raised:\nRuntimeError: Cannot find a working triton installation. More information on installing Triton can be found at https://github.com/openai/triton\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
