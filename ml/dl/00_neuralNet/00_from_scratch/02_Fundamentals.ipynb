{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e58ed126c5dce81",
   "metadata": {},
   "source": [
    "本章目标：\n",
    "- 使用第一章的构建块构建`线性回归模型`\n",
    "- 证明在第一章所做的导数的推理可以训练`线性回归模型`\n",
    "- 将上述模型扩展（依旧使用我们的构建块）到一层神经网络\n",
    "\n",
    "在接下来的第三章时，我们依旧使用相同的构建块去构建深度学习模型。\n",
    "\n",
    "在深入主题之前，先概述一下机器学习的子集： `监督学习`，接下来将重点关注如何使用神经网络去解决这类问题。"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 监督学习概述\n",
    "\n",
    "从高层次来说，机器学习指的是通过构建一种算法，用来揭示（或学习）数据之间的关系。这种关系可以是分类，回归，聚类等。监督学习可以被描述为机器学习的一个子集，专门用于查找已测量的数据特征之间的关系。\n",
    "\n",
    "在本章节会使用监督学习去解决现实世界中的房价预测问题：寻找房屋特征与房屋价值之间的关系。我们用数值去表现房屋的各个特征，也就是 `ndarray`。\n",
    "\n",
    "在这个 `ndarray` 中，每一行的长度就是数据的特征数。通常情况下，一个属性（characteristic）会有多个特征（features），但在本章中，我们将一个属性映射为一个特征。在实践中，我们通过选择一个我们想要从其他特征中预测的特征，我们将此特征称为我们的目标（target）。选择哪个特征作为目标是完全任意的，取决于要解决的问题。\n",
    "\n",
    "下图显示了监督学习描述的层次结构，从在数据中查找关系的最高级别描述，到通过训练模型来量化这些关系的最低级别，以揭示特征和目标之间的数值表示。\n",
    "\n",
    "![Overview](./images/02_supervised_learning_overview.png)\n",
    "\n",
    "本章的内容主要集中在图片的下半部分，也就是模型。"
   ],
   "id": "dbf19c3e9e6626b"
  },
  {
   "cell_type": "markdown",
   "id": "6853c16b49f85dd0",
   "metadata": {},
   "source": [
    "## 监督学习模型\n",
    "\n",
    "我们的目标是找到一个以 `ndarray` 作为输入，以 `ndarray` 作为输出的函数，这个输出的 `ndarray` 尽可能的接近目标。\n",
    "\n",
    "用 `n` 行的矩阵 `X` 表示输入，每一行都表示样本的 `k` 个特征。每一行（一个样本）使用向量表示：$x_i = \\begin{bmatrix} x_{i1} & x_{i2} & \\cdots & x_{ik} \\end{bmatrix}$ 。把所有的样本数据放在一起，我们得到一个 `n x k` 的矩阵 `X`，以下表示的是一个 `n = 3` 的矩阵：\n",
    "\n",
    "$$\n",
    "X_batch =\n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} & \\cdots & x_{1k} \\\\\n",
    "x_{21} & x_{22} & \\cdots & x_{2k} \\\\\n",
    "x_{31} & x_{32} & \\cdots & x_{3k} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "对于输入的矩阵 `X`，我们有一个 `n` 行的向量 `y`，表示我们的目标：\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "我们的目标是找到一个函数 $f$，使得 $f(X) \\approx y$。首先我们从最简单的模型：线性回归开始。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca54a767fca789",
   "metadata": {},
   "source": [
    "## 线性回归\n",
    "\n",
    "\n",
    "线性回归通常表示为：\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 \\times x_{1} + \\beta_2 \\times x_{2} + \\cdots + \\beta_k \\times x_{k} + \\epsilon\n",
    "$$\n",
    "\n",
    "\n",
    "上述公式不够直观，接下来用图示进行解释。\n",
    "\n",
    "\n",
    "## Diagram\n",
    "\n",
    "![Linear Regression](./images/02_linear_regression.png)\n",
    "\n",
    "\n",
    "也就是有一组观察数据 $x_i = \\begin{bmatrix} x_1 & x_2 & x_3 & \\cdots & x_k \\end{bmatrix} $ 和另外一组称之为 $W$ 的参数：\n",
    "\n",
    "$$\n",
    "W = \\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\\\ \\vdots \\\\ w_k \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "那么预测值就为：\n",
    "\n",
    "$$\n",
    "p_i = x_i \\times W = w_1 \\times x_{i1} + w_2 \\times x_{i2} + \\cdots + w_k \\times x_{ik}\n",
    "$$\n",
    "\n",
    "如果我们有多组观察数据，也就是上述的 $X_{batch}$ 那么预测值就是矩阵相乘：\n",
    "\n",
    "$$\n",
    "p_{batch} = X_{batch} \\times W = \n",
    "\\begin{bmatrix} \n",
    "x_{11} & x_{12} & \\cdots & x_{1k} \\\\ \n",
    "x_{21} & x_{22} & \\cdots & x_{2k} \\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\ \n",
    "x_{n1} & x_{n2} & \\cdots & x_{nk} \n",
    "\\end{bmatrix} \\times \n",
    "\\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\\\ \\vdots \\\\ w_k \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "x_{11} \\times w_1 + x_{12} \\times w_2 + \\cdots + x_{1k} \\times w_k \\\\\n",
    "x_{21} \\times w_1 + x_{22} \\times w_2 + \\cdots + x_{2k} \\times w_k \\\\\n",
    "\\vdots \\\\\n",
    "x_{n1} \\times w_1 + x_{n2} \\times w_2 + \\cdots + x_{nk} \\times w_k \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### \"训练\"模型\n",
    "\n",
    "什么是\"训练\"模型？直白地说，模型将数据作为输入，以某种方式将它们与参数相结合，并产生预测值。例如上述的线性回归模型，我们将数据 `X` 与参数 `W` 相乘，得到预测值 `p`：\n",
    "$$\n",
    "p_{batch} = \n",
    "\\begin{bmatrix}\n",
    "p_1 \\\\\n",
    "p_2 \\\\\n",
    "p_3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "为了\"训练\"模型，我们还需要额外的信息，也就是如何衡量预测值的好坏。我们将这个信息称为 `loss function`，用来衡量预测值(`p`)与目标值（`y`）之间的差异。在线性回归中，我们使用 `mean squared error` 作为 `loss function`：\n",
    "\n",
    "$$\n",
    "MSE(p_{batch},y_{batch}) = MSE \\left(\n",
    "\\begin{bmatrix}\n",
    "p_1 \\\\\n",
    "p_2 \\\\\n",
    "p_3\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3\n",
    "\\end{bmatrix}\n",
    "\\right) = \n",
    "\\frac{(y_1 - p_1)^2 + (y_2 - p_2)^2 + (y_3 - p_3)^2}{3} \n",
    "$$\n",
    "\n",
    "得到的值我们称之为 $L$。一旦我们有了这个值，我们就可以使用我们在第 1 章中看到的所有技术来计算这个数字相对于 $W$ 的每个元素的 `梯度`。然后，我们可以使用这些导数在导致 $L$ 减小的方向上更新 $W$ 的每个元素。重复上述步骤直到我们能接受的 $L$ 为止。这个过程我们称之为 `训练` 模型。\n",
    "\n",
    "\n",
    "### Diagram\n",
    "\n",
    "\n",
    "没有偏置的情况：\n",
    "\n",
    "![Linear Regression](./images/02_linear_regression_forward.png)\n",
    "\n",
    "\n",
    "\n",
    "$L$ 值可以通过以下公式计算：\n",
    "\n",
    "$$\n",
    "L = \\Lambda(\\nu(X, W), Y)\n",
    "$$\n",
    "\n",
    "\n",
    "有偏置的情况：\n",
    "\n",
    "![Linear Regression](./images/02_linear_regression_forward_bias.png)\n",
    "\n",
    "\n",
    "计算公式：\n",
    "\n",
    "$$\n",
    "p_{batch} = x_i dot W + b = \n",
    "\\begin{bmatrix}\n",
    "x_{11} \\times w_1 + x_{12} \\times w_2 + \\cdots + x_{1k} \\times w_k + b \\\\\n",
    "x_{21} \\times w_1 + x_{22} \\times w_2 + \\cdots + x_{2k} \\times w_k + b \\\\\n",
    "x_{31} \\times w_1 + x_{32} \\times w_2 + \\cdots + x_{3k} \\times w_k + b \\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "p_1 \\\\\n",
    "p_2 \\\\\n",
    "p_3\n",
    "\\end{bmatrix}\n",
    "$$"
   ],
   "id": "2e373d1a94342eae"
  },
  {
   "cell_type": "markdown",
   "id": "2427741cd898ee91",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "from typing import Callable, Dict, Tuple, List\n",
    "\n",
    "np.set_printoptions(precision=4)"
   ],
   "id": "2046496b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c905faefc0217c83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T01:29:48.762089Z",
     "start_time": "2024-05-13T01:29:48.558448Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_linear_regression(X_batch: ndarray,\n",
    "                              y_batch: ndarray,\n",
    "                              weights: Dict[str, ndarray]\n",
    "                              ) -> Tuple[float, Dict[str, ndarray]]:\n",
    "    '''\n",
    "    Forward pass for the step-by-step linear regression.\n",
    "    '''\n",
    "    # assert batch sizes of X and y are equal\n",
    "    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "\n",
    "    # assert that matrix multiplication can work\n",
    "    assert X_batch.shape[1] == weights['W'].shape[0]\n",
    "\n",
    "    # assert that B is simply a 1x1 ndarray\n",
    "    assert weights['B'].shape[0] == weights['B'].shape[1] == 1\n",
    "\n",
    "    # compute the operations on the forward pass\n",
    "    N = np.dot(X_batch, weights['W'])\n",
    "\n",
    "    P = N + weights['B']\n",
    "\n",
    "    loss = np.mean(np.power(y_batch - P, 2))\n",
    "\n",
    "    # save the information computed on the forward pass\n",
    "    forward_info: Dict[str, ndarray] = {}\n",
    "    forward_info['X'] = X_batch\n",
    "    forward_info['N'] = N\n",
    "    forward_info['P'] = P\n",
    "    forward_info['y'] = y_batch\n",
    "\n",
    "    return loss, forward_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f512dad8fda9e0",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3c60bd0bef9bb",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c819d6627a68b0",
   "metadata": {},
   "source": [
    "## 从零开始的神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ebc4dded46ee7",
   "metadata": {},
   "source": [
    "## 训练与评估我们的第一个神经网络"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
